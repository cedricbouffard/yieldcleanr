---
title: "Guide des Méta-fonctions"
subtitle: "Nouvelle API simplifiée de yieldcleanr"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Guide des Méta-fonctions - Nouvelle API}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 10,
  fig.height = 6,
  warning = FALSE,
  message = FALSE
)
```

# Introduction

Cette vignette présente la nouvelle API simplifiée de `yieldcleanr` basée sur des **méta-fonctions**. Au lieu d'avoir à retenir des dizaines de fonctions individuelles, vous pouvez maintenant utiliser un petit nombre de fonctions puissantes et flexibles.

## Pourquoi une nouvelle API ?

L'ancienne API avait **46 fonctions exportées**, ce qui rendait :
- La découverte des fonctions difficile
- La documentation dispersée
- L'apprentissage long pour les nouveaux utilisateurs

La nouvelle API n'a que **24 fonctions exportées** organisées autour de **8 méta-fonctions** principales.

# Les 8 Méta-fonctions

## 1. `filter_data()` - Tous les filtres en un seul appel

Cette fonction remplace toutes les fonctions de filtrage individuelles :
- `filter_header_status()`
- `filter_gps_status()`
- `filter_dop()`
- `filter_velocity()`
- `filter_yield_range()`
- `filter_moisture_range()`
- `filter_bounds()`

### Exemples d'utilisation

```{r filter-data-examples}
library(yieldcleanr)
library(dplyr)

# Créer des données de test
data <- tibble::tibble(
  HeaderStatus = c(1L, 33L, 33L, 0L, 1L),
  GPSStatus = c(2L, 4L, 4L, 7L, 4L),
  DOP = c(5L, 15L, 8L, 5L, 10L),
  Yield_kg_ha = c(6270, 9405, 3135, 18810, 11286),
  Moisture = c(15, 16, 15, 16, 15),
  X = c(435000, 435010, 435020, 435030, 435040),
  Y = c(5262000, 5262010, 5262020, 5262030, 5262040),
  Interval = c(2L, 2L, 2L, 2L, 2L),
  Flow = 1:5
)

# Appliquer un seul filtre
data_filtered <- filter_data(data, type = "header")
cat("Après filtre header:", nrow(data_filtered), "points\n")

# Appliquer plusieurs filtres
data_multi <- filter_data(data, type = c("header", "gps"))
cat("Après filtres header + gps:", nrow(data_multi), "points\n")

# Appliquer tous les filtres disponibles
data_all <- filter_data(data, type = "all")
cat("Après tous les filtres:", nrow(data_all), "points\n")
```

### Paramètres personnalisés

```{r filter-data-params}
# Filtre de rendement avec plage personnalisée
data_yield <- filter_data(data, 
                          type = "yield",
                          min_yield = 3000,
                          max_yield = 15000)

# Filtre de vitesse avec seuils personnalisés
data_velocity <- filter_data(data,
                             type = "velocity",
                             min_velocity = 0.5,
                             max_velocity = 8.0)

# Filtre GPS avec statut minimum personnalisé
data_gps <- filter_data(data,
                       type = "gps",
                       min_gps_status = 5)
```

## 2. `detect_anomalies()` - Détection d'anomalies unifiée

Cette fonction remplace toutes les fonctions de détection d'anomalies :
- `remove_overlap()`
- `filter_local_std()`
- `filter_velocity_jumps()`
- `filter_heading_anomalies()`
- `filter_position_outliers()`
- `apply_overlap_filter()`
- `apply_local_sd_filter()`

### Exemples d'utilisation

```{r detect-anomalies-examples}
# Créer des données avec anomalies
data <- tibble::tibble(
  X = c(435000, 435001, 435002, 435003, 435100),
  Y = c(5262000, 5262001, 5262002, 5262003, 5262100),
  Flow = c(50, 55, 300, 52, 48),  # 300 est une anomalie
  Swath = rep(240, 5),
  Interval = rep(2, 5),
  GPS_Time = 1:5
)

# Détecter les chevauchements
data_clean <- detect_anomalies(data, type = "overlap", cellsize = 0.3, max_pass = 2)

# Détecter les outliers locaux
data_clean <- detect_anomalies(data, type = "local_sd", n_swaths = 5, lsd_limit = 2.4)

# Détecter les changements brusques de vitesse
data_clean <- detect_anomalies(data, type = "velocity_jump", max_acceleration = 5)

# Détecter les anomalies de direction
data_clean <- detect_anomalies(data, type = "heading", max_heading_change = 60)

# Détecter toutes les anomalies
data_clean <- detect_anomalies(data, type = "all")
```

### Mode "detect" vs "filter"

```{r detect-anomalies-mode}
# Mode "filter" (défaut) : filtre les anomalies
data_filtered <- detect_anomalies(data, type = "local_sd", action = "filter")

# Mode "detect" : marque sans filtrer
data_marked <- detect_anomalies(data, type = "local_sd", action = "detect")
# Ajoute une colonne 'local_sd_outlier' avec TRUE/FALSE
```

## 3. `calculate_thresholds()` - Calcul des seuils unifié

Cette fonction remplace `calculate_auto_thresholds()` et offre plus de flexibilité.

### Exemples d'utilisation

```{r calculate-thresholds-examples}
# Créer des données
data <- tibble::tibble(
  Yield_kg_ha = c(6270, 7524, 8778, 10032, 11286, 6897, 8142, 9405),
  X = 435000 + 1:8,
  Y = 5262000 + 1:8,
  Moisture = c(15, 16, 15, 16, 15, 16, 15, 16)
)

# Calculer tous les seuils
thresholds <- calculate_thresholds(data, type = "all")
print(thresholds)

# Calculer seulement les seuils de rendement
thresholds_yield <- calculate_thresholds(data, type = "yield")
cat("Seuils de rendement:", thresholds_yield$yield$min_yield, "-", 
    thresholds_yield$yield$max_yield, "kg/ha\n")

# Calculer avec des paramètres personnalisés
thresholds_custom <- calculate_thresholds(data, type = "yield",
                                          yllim = 0.05, yulim = 0.95, yscale = 1.5)
```

## 4. `optimize_delays()` - Optimisation des délais unifiée

Cette fonction remplace `apply_flow_delay()` et `apply_moisture_delay()` et offre une interface plus simple pour l'optimisation du delay adjustment.

### Exemples d'utilisation

```{r optimize-delays-examples}
# Créer des données avec décalage temporel
data <- tibble::tibble(
  Flow = c(10, 15, 12, 18, 14, 16, 13, 17, 11, 19),
  Moisture = c(15, 16, 15, 16, 15, 16, 15, 16, 15, 16),
  GPS_Time = 1:10,
  X = 435000 + 1:10,
  Y = 5262000 + 1:10,
  Interval = rep(2L, 10)
)

# Optimiser seulement le délai de flux
result <- optimize_delays(data, type = "flow", delay_range = -3:3, n_iterations = 2)
cat("Délai optimal flux:", result$delays$flow, "secondes\n")

# Optimiser seulement le délai d'humidité
result <- optimize_delays(data, type = "moisture", delay_range = -3:3, n_iterations = 2)
cat("Délai optimal humidité:", result$delays$moisture, "secondes\n")

# Optimiser les deux délais
result <- optimize_delays(data, type = "both", delay_range = -3:3, n_iterations = 2)
cat("Délais optimaux - Flux:", result$delays$flow, 
    "Humidité:", result$delays$moisture, "secondes\n")

# Optimiser et appliquer automatiquement les corrections
result <- optimize_delays(data, type = "flow", 
                          delay_range = -3:3, 
                          n_iterations = 2,
                          apply_correction = TRUE)
data_corrected <- result$data
```

## 5. `convert_coordinates()` - Conversion de coordonnées

Cette fonction offre une interface unifiée pour la conversion de coordonnées.

### Exemples d'utilisation

```{r convert-coordinates-examples}
# Données en Lat/Lon
data_latlon <- tibble::tibble(
  Longitude = c(-69.856661, -69.856681),
  Latitude = c(47.506122, 47.506136)
)

# Convertir vers UTM
data_utm <- convert_coordinates(data_latlon, from = "latlon", to = "utm")
print(data_utm)

# Convertir vers UTM avec zone spécifique
data_utm <- convert_coordinates(data_latlon, from = "latlon", to = "utm", zone = 18)
```

## 6. `convert_yield_units()` - Conversion de rendement

Cette fonction remplace `convert_flow_to_yield()` et offre plus d'options de conversion.

### Exemples d'utilisation

```{r convert-yield-examples}
# Données avec flux en lbs/s
data <- tibble::tibble(
  Flow = c(50, 55, 52),
  Interval = c(2, 2, 2),
  Distance = c(87, 87, 87),
  Swath = c(240, 240, 240)
)

# Convertir flux (lbs/s) vers kg/ha
data_yield <- convert_yield_units(data, from = "flow_lbs_s", to = "kg_ha")
print(data_yield)

# Convertir kg/ha vers bu/acre (maïs)
data_imperial <- convert_yield_units(data_yield, from = "kg_ha", to = "bu_acre", crop_type = "maize")
print(data_imperial)

# Convertir vers tonnes/ha
data_tons <- convert_yield_units(data_yield, from = "kg_ha", to = "t_ha")
print(data_tons)
```

## 7. `anonymize_data()` - Anonymisation unifiée

Cette fonction remplace `anonymize_coordinates()`, `remove_sensitive_attributes()`, et `anonymize_yield_data()`.

### Exemples d'utilisation

```{r anonymize-examples}
# Créer des données avec informations sensibles
data <- tibble::tibble(
  X = c(435000, 435010, 435020),
  Y = c(5262000, 5262010, 5262020),
  Flow = c(50, 55, 52),
  Serial = c("ABC123", "ABC123", "ABC123"),
  FieldID = c("Field001", "Field001", "Field001")
)

# Anonymiser uniquement les coordonnées (décalage)
data_anon <- anonymize_data(data, type = "coordinates", method = "translation")
print(data_anon)

# Anonymiser uniquement les attributs sensibles
data_anon <- anonymize_data(data, type = "attributes")
print(data_anon)

# Anonymiser complètement (coordonnées + attributs)
data_anon <- anonymize_data(data, type = "full", method = "translation")
print(data_anon)

# Anonymiser avec rotation au lieu de décalage
data_anon <- anonymize_data(data, type = "coordinates", method = "rotation")
print(data_anon)
```

## 8. `export_data()` - Export unifié

Cette fonction remplace `export_raster()` et `save_raster()` et offre une interface unifiée pour tous les formats d'export.

### Exemples d'utilisation

```{r export-examples}
# Créer des données
data <- tibble::tibble(
  Longitude = c(-69.856661, -69.856681),
  Latitude = c(47.506122, 47.506136),
  Yield_kg_ha = c(6270, 9405)
)

# Export CSV
temp_csv <- tempfile(fileext = ".csv")
export_data(data, temp_csv, format = "csv")
cat("Export CSV:", temp_csv, "\n")

# Export GeoJSON (si sf est installé)
if (requireNamespace("sf", quietly = TRUE)) {
  data_sf <- sf::st_as_sf(data, coords = c("Longitude", "Latitude"), crs = 4326)
  temp_geojson <- tempfile(fileext = ".geojson")
  export_data(data_sf, temp_geojson)
  cat("Export GeoJSON:", temp_geojson, "\n")
}

# Export avec détection automatique du format
temp_file <- tempfile(fileext = ".csv")
export_data(data, temp_file)  # Détecte CSV depuis l'extension

# Nettoyage
unlink(temp_csv)
if (exists("temp_geojson")) unlink(temp_geojson)
unlink(temp_file)
```

# Pipeline complet avec les méta-fonctions

Voici un exemple de pipeline complet utilisant les méta-fonctions :

```{r full-pipeline}
library(yieldcleanr)
library(dplyr)

# 1. Charger les données
file_path <- system.file("extdata", "sample1.txt", package = "yieldcleanr")
data_raw <- read_yield_data(file_path)

# 2. Convertir les coordonnées
data <- convert_coordinates(data_raw, from = "latlon", to = "utm")

# 3. Convertir le flux en rendement
data <- convert_yield_units(data, from = "flow_lbs_s", to = "kg_ha")

# 4. Calculer les seuils
thresholds <- calculate_thresholds(data, type = "all")

# 5. Appliquer les filtres de base
data <- filter_data(data, type = c("header", "gps", "velocity", "yield", "moisture"))

# 6. Détecter et filtrer les anomalies
data <- detect_anomalies(data, type = c("overlap", "local_sd"))

# 7. Optimiser les délais (si nécessaire)
# result <- optimize_delays(data, type = "both")
# data <- result$data

# 8. Anonymiser (si nécessaire)
# data <- anonymize_data(data, type = "full")

# 9. Exporter
# export_data(data, "output.csv", format = "csv")

cat("Pipeline terminé! Points finaux:", nrow(data), "\n")
```

# Tableau récapitulatif

| Ancienne fonction | Nouvelle méta-fonction | Paramètre `type` |
|-------------------|------------------------|------------------|
| `filter_header_status()` | `filter_data()` | `"header"` |
| `filter_gps_status()` | `filter_data()` | `"gps"` |
| `filter_dop()` | `filter_data()` | `"dop"` |
| `filter_velocity()` | `filter_data()` | `"velocity"` |
| `filter_yield_range()` | `filter_data()` | `"yield"` |
| `filter_moisture_range()` | `filter_data()` | `"moisture"` |
| `filter_bounds()` | `filter_data()` | `"bounds"` |
| `remove_overlap()` | `detect_anomalies()` | `"overlap"` |
| `filter_local_std()` | `detect_anomalies()` | `"local_sd"` |
| `filter_velocity_jumps()` | `detect_anomalies()` | `"velocity_jump"` |
| `filter_heading_anomalies()` | `detect_anomalies()` | `"heading"` |
| `filter_position_outliers()` | `detect_anomalies()` | `"position"` |
| `apply_overlap_filter()` | `detect_anomalies()` | `"overlap"` |
| `apply_local_sd_filter()` | `detect_anomalies()` | `"local_sd"` |
| `calculate_auto_thresholds()` | `calculate_thresholds()` | `"all"` ou `"yield"`, etc. |
| `apply_flow_delay()` | `optimize_delays()` | `"flow"` |
| `apply_moisture_delay()` | `optimize_delays()` | `"moisture"` |
| `convert_flow_to_yield()` | `convert_yield_units()` | `"flow_lbs_s"` → `"kg_ha"` |
| `anonymize_coordinates()` | `anonymize_data()` | `"coordinates"` |
| `remove_sensitive_attributes()` | `anonymize_data()` | `"attributes"` |
| `anonymize_yield_data()` | `anonymize_data()` | `"full"` |
| `export_raster()` | `export_data()` | `"raster"` |
| `save_raster()` | `export_data()` | `"raster"` |

# Conclusion

Les méta-fonctions offrent une interface plus simple et plus cohérente pour travailler avec yieldcleanr. Au lieu de retenir des dizaines de fonctions, vous n'avez besoin que de **8 méta-fonctions** pour accomplir la plupart des tâches de nettoyage de données de rendement.

Pour les cas d'utilisation avancés, les fonctions individuelles sont toujours disponibles en interne, mais la nouvelle API recommandée utilise les méta-fonctions présentées dans cette vignette.
